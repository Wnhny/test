{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f903127-e9a2-4330-8340-de29cd8ebe62",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99a1981-9af6-46aa-9cc2-9c57fc978de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26cd66a-f832-43e0-976b-9478c30bc3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data1ramp0.4dt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d725a3-7249-4031-8440-bf2bd0d473b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2016, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d468d9-770b-4c54-bb8b-0edf922d50dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                 dt  PI_feedwaterPump.y     gain.y  PTarget.y   gain1.y  \\\n",
       "0     0.000000e+00          15426218.0  10.500000        1.0  0.000333   \n",
       "1     1.000000e-10          15426218.0  10.500000        1.0  0.000333   \n",
       "2     0.000000e+00          15426218.0  10.500000        1.0  0.000333   \n",
       "3     1.506334e-01          15287873.0  10.500322        1.0  0.000333   \n",
       "4     0.000000e+00          15287873.0  10.500322        1.0  0.000333   \n",
       "...            ...                 ...        ...        ...       ...   \n",
       "2011  0.000000e+00           2344981.2   4.285714        0.4  0.000333   \n",
       "2012  1.000000e+01           2344981.8   4.285714        0.4  0.000333   \n",
       "2013  0.000000e+00           2344981.8   4.285714        0.4  0.000333   \n",
       "2014  1.000000e+01           2344982.2   4.285714        0.4  0.000333   \n",
       "2015  0.000000e+00           2344982.2   4.285714        0.4  0.000333   \n",
       "\n",
       "      GW_CWS1_Valve_Ramp_Cold_HT_out3.y  turbineStress.stress.inStress  \\\n",
       "0                                  0.02                   4.150000e-13   \n",
       "1                                  0.02                   4.150000e-13   \n",
       "2                                  0.02                   4.150000e-13   \n",
       "3                                  0.02                   4.150000e-13   \n",
       "4                                  0.02                   4.150000e-13   \n",
       "...                                 ...                            ...   \n",
       "2011                               0.02                   5.192716e+01   \n",
       "2012                               0.02                   5.192712e+01   \n",
       "2013                               0.02                   5.177184e+01   \n",
       "2014                               0.02                   5.177180e+01   \n",
       "2015                               0.02                   5.161699e+01   \n",
       "\n",
       "      turbineStress.stress.outStress  simpleGenerator.summary.P_el  \\\n",
       "0                           0.000000                     633421800   \n",
       "1                           0.000000                     633421800   \n",
       "2                           0.000000                     633421800   \n",
       "3                           0.000000                     616475300   \n",
       "4                           0.000000                     616475300   \n",
       "...                              ...                           ...   \n",
       "2011                        6.284328                     244788290   \n",
       "2012                        6.283162                     244788400   \n",
       "2013                        6.266063                     244788400   \n",
       "2014                        6.264914                     244788500   \n",
       "2015                        6.247855                     244788500   \n",
       "\n",
       "      quadruple1.p  quadruple1.T  quadruple2.p  quadruple2.T  \n",
       "0        51.220000     559.85000    262.107640     549.88830  \n",
       "1        51.220000     559.85000    262.107640     549.88830  \n",
       "2        51.220000     559.85000    262.107640     549.88830  \n",
       "3        49.472336     550.16406    257.755300     546.68225  \n",
       "4        49.472336     550.16406    257.755300     546.68225  \n",
       "...            ...           ...           ...           ...  \n",
       "2011     19.875187     486.52414    107.092300     514.30830  \n",
       "2012     19.875190     486.52448    107.092330     514.30860  \n",
       "2013     19.875190     486.52448    107.092330     514.30860  \n",
       "2014     19.875196     486.52480    107.092354     514.30890  \n",
       "2015     19.875196     486.52480    107.092354     514.30890  \n",
       "\n",
       "[2016 rows x 13 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091fd4e6-40fe-4492-a21f-8c72654690ce",
   "metadata": {},
   "source": [
    "输入：给水PI_feedwaterPump.y，给煤gain.y，功率指令PTarget.y，速率指令（gain1.y），限制指令GW_CWS1_Valve_Ramp_Cold_HT_out3.y，dt\n",
    "输出：电功率simpleGenerator.summary.P_el，主气压quadruple2.p，再热压力（quadruple1.p），主蒸汽温度，内应力turbineStress.stress.inStress，外turbineStress.stress.outStress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b45790c-47de-4a4c-9e3e-54829c32d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.mean = self.data.iloc[:, 0:12].mean()\n",
    "        self.std = self.data.iloc[:, 0:12].std()\n",
    "        self.data.iloc[:, 0:12] = self.data.iloc[:, 0:12].astype(float)\n",
    "        self.data.iloc[:, 0:12] = (self.data.iloc[:, 0:12] - self.mean) / self.std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data.iloc[idx + 1, 0:6].values\n",
    "        # tm_values = tm_values.astype(np.float32)\n",
    "        y = self.data.iloc[6, 12]\n",
    "\n",
    "        # 检查数据类型并尝试转换\n",
    "        try:\n",
    "            tm = torch.tensor(x, dtype=torch.float32, device=device)\n",
    "            t0 = torch.tensor(y, dtype=torch.float32, device=device)\n",
    "        except TypeError:\n",
    "            raise ValueError(f\"Error converting data at index {idx}. tm_values: {x}, t0_value: {y}\")\n",
    "\n",
    "        return tm, t0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "519ec97f-6051-4396-8108-f9d55de4ed67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>PI_feedwaterPump.y</th>\n",
       "      <th>gain.y</th>\n",
       "      <th>PTarget.y</th>\n",
       "      <th>gain1.y</th>\n",
       "      <th>GW_CWS1_Valve_Ramp_Cold_HT_out3.y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>15426218.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>15426218.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>15426218.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.506334e-01</td>\n",
       "      <td>15287873.0</td>\n",
       "      <td>10.500322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>15287873.0</td>\n",
       "      <td>10.500322</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2344981.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>2344981.8</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2344981.8</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>2344982.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2344982.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dt  PI_feedwaterPump.y     gain.y  PTarget.y   gain1.y  \\\n",
       "0     0.000000e+00          15426218.0  10.500000        1.0  0.000333   \n",
       "1     1.000000e-10          15426218.0  10.500000        1.0  0.000333   \n",
       "2     0.000000e+00          15426218.0  10.500000        1.0  0.000333   \n",
       "3     1.506334e-01          15287873.0  10.500322        1.0  0.000333   \n",
       "4     0.000000e+00          15287873.0  10.500322        1.0  0.000333   \n",
       "...            ...                 ...        ...        ...       ...   \n",
       "2011  0.000000e+00           2344981.2   4.285714        0.4  0.000333   \n",
       "2012  1.000000e+01           2344981.8   4.285714        0.4  0.000333   \n",
       "2013  0.000000e+00           2344981.8   4.285714        0.4  0.000333   \n",
       "2014  1.000000e+01           2344982.2   4.285714        0.4  0.000333   \n",
       "2015  0.000000e+00           2344982.2   4.285714        0.4  0.000333   \n",
       "\n",
       "      GW_CWS1_Valve_Ramp_Cold_HT_out3.y  \n",
       "0                                  0.02  \n",
       "1                                  0.02  \n",
       "2                                  0.02  \n",
       "3                                  0.02  \n",
       "4                                  0.02  \n",
       "...                                 ...  \n",
       "2011                               0.02  \n",
       "2012                               0.02  \n",
       "2013                               0.02  \n",
       "2014                               0.02  \n",
       "2015                               0.02  \n",
       "\n",
       "[2016 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c0f35d6-1d6f-4f9b-a25c-18dd734296a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUModel(\n",
      "  (gru): GRU(6, 64, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size=6, hidden_size=64, output_size=7, num_layers=2):\n",
    "        super(GRUModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # GRU层\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True  # 输入和输出张量的形状为 (batch, seq, feature)\n",
    "        )\n",
    "        \n",
    "        # 输出层\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, sequence_length, input_size)\n",
    "        \n",
    "        # 初始化隐藏状态\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # 前向传播 GRU\n",
    "        out, _ = self.gru(x, h0)\n",
    "        \n",
    "        # 解码最后一个时间步的隐藏状态\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out\n",
    "\n",
    "# 创建模型实例\n",
    "model = GRUModel(input_size=6, hidden_size=64, output_size=7, num_layers=2)\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac41661-7fad-4636-9d7f-d6884bafd623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_267056\\817424074.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0       633421800.0\n",
      "1       633421800.0\n",
      "2       633421800.0\n",
      "3       616475300.0\n",
      "4       616475300.0\n",
      "           ...     \n",
      "2011    244788290.0\n",
      "2012    244788400.0\n",
      "2013    244788400.0\n",
      "2014    244788500.0\n",
      "2015    244788500.0\n",
      "Name: simpleGenerator.summary.P_el, Length: 2016, dtype: float64' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  self.data.iloc[:, 0:12] = self.data.iloc[:, 0:12].astype(float)\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset('data1ramp0.4dt.csv')\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=False, drop_last=True)\n",
    "\n",
    "# 数据划分\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# 使用slice而不是random_split\n",
    "train_dataset = torch.utils.data.Subset(dataset, range(0, train_size))\n",
    "val_dataset = torch.utils.data.Subset(dataset, range(train_size, train_size + val_size))\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=5, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b92ce247-faf7-4cb9-b029-4814d9890f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\OMPRL\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx should also be 2-D but got 3-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m tm, t0 \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 反标准化预测的输出\u001b[39;00m\n\u001b[0;32m     24\u001b[0m outputs_inv_std \u001b[38;5;241m=\u001b[39m inverse_standardize(outputs, dataset\u001b[38;5;241m.\u001b[39mmean[\u001b[38;5;241m0\u001b[39m], dataset\u001b[38;5;241m.\u001b[39mstd[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\OMPRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\OMPRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m, in \u001b[0;36mGRUModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 前向传播 GRU\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 解码最后一个时间步的隐藏状态\u001b[39;00m\n\u001b[0;32m     32\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\OMPRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\OMPRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\OMPRL\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1078\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1076\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1078\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1079\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched 2-D input, hx should also be 2-D but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1080\u001b[0m         hx \u001b[38;5;241m=\u001b[39m hx\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx should also be 2-D but got 3-D tensor"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 学习率动态调整\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True)\n",
    "\n",
    "# Early stopping\n",
    "n_epochs_stop = 10\n",
    "epochs_no_improve = 0\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "predicted_vals = []\n",
    "actual_vals = []\n",
    "\n",
    "for epoch in range(50):  # max epoch\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        tm, t0 = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(tm)\n",
    "        # 反标准化预测的输出\n",
    "        outputs_inv_std = inverse_standardize(outputs, dataset.mean[0], dataset.std[0])\n",
    "        # t0_inv_std = inverse_standardize(t0, dataset.mean_t0, dataset.std_t0)\n",
    "\n",
    "        loss = criterion(outputs_inv_std, t0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "    # Validation loss,Maybe it is ok\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs, labels = data\n",
    "            outputs = model(tm)\n",
    "            # data取的不对，这不是x——》Y的数据集\n",
    "\n",
    "            # 反标准化预测的输出\n",
    "            outputs_inv_std = inverse_standardize(outputs, dataset.mean[0], dataset.std[0])\n",
    "            # t0_inv_std = inverse_standardize(t0, dataset.mean_t0, dataset.std_t0)\n",
    "            # t0也是标准化后的，应该反标准化\n",
    "            # 更改了初始化部分，t0未标准化\n",
    "            loss = criterion(outputs_inv_std, t0)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # # 预测与实际，方便出图\n",
    "            # predicted_vals = outputs_inv_std\n",
    "            # actual_vals = t0_inv_std\n",
    "            #\n",
    "        # if epoch == 9:\n",
    "        #     predicted_vals.extend(outputs_inv_std.cpu().numpy().tolist())\n",
    "        #     actual_vals.extend(t0.cpu().numpy().tolist())\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    # 早停条件\n",
    "    if val_loss < min_val_loss:\n",
    "        epochs_no_improve = 0\n",
    "        min_val_loss = val_loss\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    if epochs_no_improve == n_epochs_stop:\n",
    "        print(\"Early stopping!\")\n",
    "        break\n",
    "    print(f\"Epoch {epoch + 1}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d6547eb-c788-4fba-8069-34d9755ee96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9934,  1.5866,  1.4073,  1.7046,  0.9998,     nan],\n",
       "        [-0.9934,  1.5866,  1.4073,  1.7046,  0.9998,     nan],\n",
       "        [-0.9632,  1.5617,  1.4075,  1.7046,  0.9998,     nan],\n",
       "        [-0.9934,  1.5617,  1.4075,  1.7046,  0.9998,     nan],\n",
       "        [-0.9591,  1.5334,  1.4076,  1.7046,  0.9998,     nan]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c56216e4-5f96-4b0f-9bfc-f35e4c18cd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29df2fa-b16a-4d0b-85b1-496cf26ec012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OMPRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "48fcca7cbc362ee6028182ccbdb3d093cdfefd3e47522f76612accc97b0634a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
