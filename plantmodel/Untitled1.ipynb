{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11fa76f0-4312-460d-8b94-fd8e518e522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1064881791906100\n",
      "GRUModel(\n",
      "  (gru): GRU(5, 64, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=7, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\OMPRL\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/806], Loss: 54310776285954048.0000\n",
      "Epoch [1/10], Step [200/806], Loss: 54930677505720320.0000\n",
      "Epoch [1/10], Step [300/806], Loss: 45267709759324160.0000\n",
      "Epoch [1/10], Step [400/806], Loss: 18118867146506240.0000\n",
      "Epoch [1/10], Step [500/806], Loss: 8324807871430656.0000\n",
      "Epoch [1/10], Step [600/806], Loss: 8532853939765248.0000\n",
      "Epoch [1/10], Step [700/806], Loss: 8548983152574464.0000\n",
      "Epoch [1/10], Step [800/806], Loss: 8555928114692096.0000\n",
      "Test Loss: 8558695354679134.0000\n",
      "Epoch [2/10], Step [100/806], Loss: 54310763401052160.0000\n",
      "Epoch [2/10], Step [200/806], Loss: 54930668915785728.0000\n",
      "Epoch [2/10], Step [300/806], Loss: 45267696874422272.0000\n",
      "Epoch [2/10], Step [400/806], Loss: 18118862851538944.0000\n",
      "Epoch [2/10], Step [500/806], Loss: 8324805187076096.0000\n",
      "Epoch [2/10], Step [600/806], Loss: 8532850181668864.0000\n",
      "Epoch [2/10], Step [700/806], Loss: 8548979394478080.0000\n",
      "Epoch [2/10], Step [800/806], Loss: 8555924356595712.0000\n",
      "Test Loss: 8558692027142590.0000\n",
      "Epoch [3/10], Step [100/806], Loss: 54310754811117568.0000\n",
      "Epoch [3/10], Step [200/806], Loss: 54930660325851136.0000\n",
      "Epoch [3/10], Step [300/806], Loss: 45267688284487680.0000\n",
      "Epoch [3/10], Step [400/806], Loss: 18118858556571648.0000\n",
      "Epoch [3/10], Step [500/806], Loss: 8324801965850624.0000\n",
      "Epoch [3/10], Step [600/806], Loss: 8532845886701568.0000\n",
      "Epoch [3/10], Step [700/806], Loss: 8548976710123520.0000\n",
      "Epoch [3/10], Step [800/806], Loss: 8555921672241152.0000\n",
      "Test Loss: 8558688627846073.0000\n",
      "Epoch [4/10], Step [100/806], Loss: 54310754811117568.0000\n",
      "Epoch [4/10], Step [200/806], Loss: 54930647440949248.0000\n",
      "Epoch [4/10], Step [300/806], Loss: 45267679694553088.0000\n",
      "Epoch [4/10], Step [400/806], Loss: 18118852114120704.0000\n",
      "Epoch [4/10], Step [500/806], Loss: 8324798207754240.0000\n",
      "Epoch [4/10], Step [600/806], Loss: 8532842128605184.0000\n",
      "Epoch [4/10], Step [700/806], Loss: 8548972952027136.0000\n",
      "Epoch [4/10], Step [800/806], Loss: 8555917914144768.0000\n",
      "Test Loss: 8558685271073985.0000\n",
      "Epoch [5/10], Step [100/806], Loss: 54310741926215680.0000\n",
      "Epoch [5/10], Step [200/806], Loss: 54930647440949248.0000\n",
      "Epoch [5/10], Step [300/806], Loss: 45267679694553088.0000\n",
      "Epoch [5/10], Step [400/806], Loss: 18118847819153408.0000\n",
      "Epoch [5/10], Step [500/806], Loss: 8324794986528768.0000\n",
      "Epoch [5/10], Step [600/806], Loss: 8532838907379712.0000\n",
      "Epoch [5/10], Step [700/806], Loss: 8548969730801664.0000\n",
      "Epoch [5/10], Step [800/806], Loss: 8555914692919296.0000\n",
      "Test Loss: 8558681930248557.0000\n",
      "Epoch [6/10], Step [100/806], Loss: 54310729041313792.0000\n",
      "Epoch [6/10], Step [200/806], Loss: 54930634556047360.0000\n",
      "Epoch [6/10], Step [300/806], Loss: 45267662514683904.0000\n",
      "Epoch [6/10], Step [400/806], Loss: 18118841376702464.0000\n",
      "Epoch [6/10], Step [500/806], Loss: 8324791765303296.0000\n",
      "Epoch [6/10], Step [600/806], Loss: 8532836223025152.0000\n",
      "Epoch [6/10], Step [700/806], Loss: 8548965972705280.0000\n",
      "Epoch [6/10], Step [800/806], Loss: 8555910934822912.0000\n",
      "Test Loss: 8558678568160915.0000\n",
      "Epoch [7/10], Step [100/806], Loss: 54310720451379200.0000\n",
      "Epoch [7/10], Step [200/806], Loss: 54930625966112768.0000\n",
      "Epoch [7/10], Step [300/806], Loss: 45267653924749312.0000\n",
      "Epoch [7/10], Step [400/806], Loss: 18118839229218816.0000\n",
      "Epoch [7/10], Step [500/806], Loss: 8324788544077824.0000\n",
      "Epoch [7/10], Step [600/806], Loss: 8532832464928768.0000\n",
      "Epoch [7/10], Step [700/806], Loss: 8548963288350720.0000\n",
      "Epoch [7/10], Step [800/806], Loss: 8555908250468352.0000\n",
      "Test Loss: 8558675214046603.0000\n",
      "Epoch [8/10], Step [100/806], Loss: 54310720451379200.0000\n",
      "Epoch [8/10], Step [200/806], Loss: 54930613081210880.0000\n",
      "Epoch [8/10], Step [300/806], Loss: 45267645334814720.0000\n",
      "Epoch [8/10], Step [400/806], Loss: 18118832786767872.0000\n",
      "Epoch [8/10], Step [500/806], Loss: 8324785322852352.0000\n",
      "Epoch [8/10], Step [600/806], Loss: 8532829243703296.0000\n",
      "Epoch [8/10], Step [700/806], Loss: 8548959530254336.0000\n",
      "Epoch [8/10], Step [800/806], Loss: 8555904492371968.0000\n",
      "Test Loss: 8558671843985631.0000\n",
      "Epoch [9/10], Step [100/806], Loss: 54310711861444608.0000\n",
      "Epoch [9/10], Step [200/806], Loss: 54930613081210880.0000\n",
      "Epoch [9/10], Step [300/806], Loss: 45267645334814720.0000\n",
      "Epoch [9/10], Step [400/806], Loss: 18118828491800576.0000\n",
      "Epoch [9/10], Step [500/806], Loss: 8324781564755968.0000\n",
      "Epoch [9/10], Step [600/806], Loss: 8532825485606912.0000\n",
      "Epoch [9/10], Step [700/806], Loss: 8548956309028864.0000\n",
      "Epoch [9/10], Step [800/806], Loss: 8555901271146496.0000\n",
      "Test Loss: 8558668487213543.0000\n",
      "Epoch [10/10], Step [100/806], Loss: 54310694681575424.0000\n",
      "Epoch [10/10], Step [200/806], Loss: 54930600196308992.0000\n",
      "Epoch [10/10], Step [300/806], Loss: 45267636744880128.0000\n",
      "Epoch [10/10], Step [400/806], Loss: 18118822049349632.0000\n",
      "Epoch [10/10], Step [500/806], Loss: 8324778880401408.0000\n",
      "Epoch [10/10], Step [600/806], Loss: 8532822801252352.0000\n",
      "Epoch [10/10], Step [700/806], Loss: 8548952550932480.0000\n",
      "Epoch [10/10], Step [800/806], Loss: 8555897513050112.0000\n",
      "Test Loss: 8558665162334776.0000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CustomDataset' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 166\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# 反标准化预测的输出\u001b[39;00m\n\u001b[0;32m    165\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(tm)\n\u001b[1;32m--> 166\u001b[0m outputs_inv_std \u001b[38;5;241m=\u001b[39m inverse_standardize(outputs, \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m[\u001b[38;5;241m0\u001b[39m], dataset\u001b[38;5;241m.\u001b[39mstd[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# t0_inv_std = inverse_standardize(t0, dataset.mean_t0, dataset.std_t0)\u001b[39;00m\n\u001b[0;32m    169\u001b[0m predicted_vals\u001b[38;5;241m.\u001b[39mextend(outputs_inv_std\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CustomDataset' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1064881791906100)\n",
    "print(torch.initial_seed())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "def inverse_standardize(tensor, mean, std):\n",
    "    return tensor * std + mean\n",
    "\n",
    "\n",
    "# 反标准化\n",
    "\n",
    "# DataLoader部分\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data =  pd.read_csv(\"data1ramp0.4dt.csv\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data.iloc[idx, :5].values  # 前5列作为输入\n",
    "        y = self.data.iloc[idx, 5:12].values  # 后7列作为输出\n",
    "        # 重塑 x 为 (1, 5)，表示1个时间步，每步5个特征\n",
    "        x = x.reshape(1, -1)\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size=5, hidden_size=64, output_size=7, num_layers=2):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # GRU层\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # 全连接层，用于生成输出\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 初始化隐藏状态\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # GRU前向传播\n",
    "        out, _ = self.gru(x, h0)\n",
    "\n",
    "        # 我们只需要最后一个时间步的输出\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "\n",
    "# 创建模型实例\n",
    "model = GRUModel(input_size=5, hidden_size=64, output_size=7, num_layers=2).to(device)\n",
    "\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)\n",
    "\n",
    "\n",
    "# 数据加载\n",
    "dataset = CustomDataset('data1ramp0.4dt.csv')\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=False, drop_last=True)\n",
    "\n",
    "# 数据划分\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# 使用slice而不是random_split\n",
    "train_dataset = torch.utils.data.Subset(dataset, range(0, train_size))\n",
    "val_dataset = torch.utils.data.Subset(dataset, range(train_size, train_size + val_size))\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, drop_last=True)\n",
    "\n",
    "# Unit\n",
    "# model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 学习率动态调整\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True)\n",
    "num_epochs = 10\n",
    "# Early stopping\n",
    "n_epochs_stop = 10\n",
    "epochs_no_improve = 0\n",
    "min_val_loss = float('inf')\n",
    "\n",
    "predicted_vals = []\n",
    "actual_vals = []\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 确保输入形状正确：(batch_size, sequence_length, input_size)\n",
    "        # 在这里，sequence_length = 1\n",
    "        if inputs.dim() == 2:\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Validation loss,Maybe it is ok\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            if inputs.dim() == 2:\n",
    "                inputs = inputs.unsqueeze(1)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "        average_loss = total_loss / len(val_loader)\n",
    "        print(f'Test Loss: {average_loss:.4f}')\n",
    "\n",
    "            # # 预测与实际，方便出图\n",
    "            # predicted_vals = outputs_inv_std\n",
    "            # actual_vals = t0_inv_std\n",
    "            #\n",
    "        # if epoch == 9:\n",
    "        #     predicted_vals.extend(outputs_inv_std.cpu().numpy().tolist())\n",
    "        #     actual_vals.extend(t0.cpu().numpy().tolist())\n",
    "\n",
    "    # scheduler.step(val_loss)\n",
    "    # # 早停条件\n",
    "    # if val_loss < min_val_loss:\n",
    "    #     epochs_no_improve = 0\n",
    "    #     min_val_loss = val_loss\n",
    "    # else:\n",
    "    #     epochs_no_improve += 1\n",
    "    # if epochs_no_improve == n_epochs_stop:\n",
    "    #     print(\"Early stopping!\")\n",
    "    #     break\n",
    "    # print(f\"Epoch {epoch + 1}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "    tm, t0 = data\n",
    "\n",
    "    # 反标准化预测的输出\n",
    "    outputs = model(tm)\n",
    "    outputs_inv_std = inverse_standardize(outputs, dataset.mean[0], dataset.std[0])\n",
    "    # t0_inv_std = inverse_standardize(t0, dataset.mean_t0, dataset.std_t0)\n",
    "\n",
    "    predicted_vals.extend(outputs_inv_std.detach().cpu().numpy().tolist())\n",
    "    actual_vals.extend(t0.cpu().detach().numpy().tolist())\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(predicted_vals, label='Predicted')\n",
    "plt.plot(actual_vals, label='Actual t0')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.title('Comparison of Predicted Results and Actual t0 Values')\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.plot(predict.detach().cpu().numpy(), label='Predicted')\n",
    "# plt.plot(actual_vals, label='Actual t0')\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Value')\n",
    "# plt.legend()\n",
    "# plt.title('Comparison of Predicted Results and Actual t0 Values')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ddca84-dce3-41b3-b219-47ec57bfee39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mx\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04d0c1f-5ea4-4066-a3d8-755f6fe145eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+01, 2.3450e+06, 4.2857e+00, 4.0000e-01, 3.3333e-04]],\n",
       "\n",
       "        [[0.0000e+00, 2.3450e+06, 4.2857e+00, 4.0000e-01, 3.3333e-04]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b28b29e-6364-4101-be30-3321d2358319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454d0aff-31dc-4bcf-84b1-e8b180c4538c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000e-02, 5.1772e+01, 6.2649e+00, 2.4479e+08, 1.9875e+01, 4.8652e+02,\n",
       "         1.0709e+02],\n",
       "        [2.0000e-02, 5.1617e+01, 6.2479e+00, 2.4479e+08, 1.9875e+01, 4.8652e+02,\n",
       "         1.0709e+02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9b0b11-fccc-4bcf-8bf6-5939c5909221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4339add5-4ef7-4eb4-a764-530e6ccee248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.5602e+15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b91eb-b9cd-4ff2-a1e3-bbe7ffc0038f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
